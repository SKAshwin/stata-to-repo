{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from pandas import read_stata\n",
    "import pandas as pd\n",
    "from lcsscaseapi.client import LCSSClient\n",
    "from lcsscaseapi.types import USCircuitCaseMeta, USJudge, JudgeRuling\n",
    "import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = read_stata(\"BloombergCASELEVEL_Touse.dta\")\n",
    "\n",
    "print(len(df[\"caseid\"]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "387898\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "df = df.head(n=1000) # sub sample to play with"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "def create_case_meta(row):\n",
    "    case_id = row['caseid']\n",
    "    circuit_num = row['Circuit']\n",
    "    circuit_name = USCircuitCaseMeta.CIRCUITS[circuit_num]\n",
    "    self_cite = row['citation']\n",
    "    docket_number = row['docketnumber']\n",
    "    if not pd.isnull(row['date']):\n",
    "        date = datetime.date(int(row['year']), int(row['month']), int(row['day']))\n",
    "    else:\n",
    "        date = None\n",
    "    tags = construct_tags(row)\n",
    "    outcome = construct_outcome(row)\n",
    "\n",
    "    return USCircuitCaseMeta(case_id=case_id, circuit_name=circuit_name, self_cite=self_cite, \n",
    "                                docket_number=docket_number, date=date, tags=tags, outcome = outcome)\n",
    "\n",
    "def construct_tags(row):\n",
    "    tags = []\n",
    "    if row['Criminal'] == 1:\n",
    "        tags.append('CRIMINAL')\n",
    "    \n",
    "    if row['Civil_Rights'] == 1:\n",
    "        tags.append('CIVIL RIGHTS')\n",
    "\n",
    "    if row['First_Amendment'] == 1:\n",
    "        tags.append('FIRST AMENDMENT')\n",
    "    \n",
    "    if row['Due_Process'] == 1:\n",
    "        tags.append('DUE PROCESS')\n",
    "    \n",
    "    if row['Privacy'] == 1:\n",
    "        tags.append('PRIVACY')\n",
    "    \n",
    "    if row['Labor_Relations'] == 1:\n",
    "        tags.append('LABOR RELATIONS')\n",
    "    \n",
    "    if row['Econ_Activity'] == 1:\n",
    "        tags.append('ECONOMIC ACTIVITY')\n",
    "\n",
    "    if row['Miscellanous'] == 1:\n",
    "        tags.append('MISCELLANEOUS')\n",
    "\n",
    "    return tags\n",
    "\n",
    "def construct_outcome(row):\n",
    "    outcomes = []\n",
    "\n",
    "    if row[\"Affirmed\"] == 1:\n",
    "        outcomes.append(\"AFFIRMED\")\n",
    "    \n",
    "    if row[\"AffirmedInPart\"] == 1:\n",
    "        outcomes.append(\"AFFIRMED (IN PART)\")\n",
    "    \n",
    "    if row[\"Reversed\"] == 1:\n",
    "        outcomes.append(\"REVERSED\")\n",
    "\n",
    "    if row[\"ReversedInPart\"] == 1:\n",
    "        outcomes.append(\"REVERSED (IN PART)\")\n",
    "    \n",
    "    if row[\"Vacated\"] == 1:\n",
    "        outcomes.append(\"VACATED\")\n",
    "\n",
    "    if row[\"VacatedInPart\"] == 1:\n",
    "        outcomes.append(\"VACATED (IN PART)\")\n",
    "\n",
    "    if row[\"Remanded\"] == 1:\n",
    "        outcomes.append(\"REMANDED\")\n",
    "\n",
    "    if len(outcomes) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return \",\".join(outcomes)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# takes 39.5s to run\n",
    "cases = df.apply(create_case_meta, axis=1)\n",
    "\n",
    "print(len(cases))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "load_dotenv()\n",
    "\n",
    "USERNAME = os.getenv('ACCOUNT')\n",
    "PWD = os.getenv('PASSWORD')\n",
    "\n",
    "client = LCSSClient(username=USERNAME, password=PWD)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "#returned_cases = client.upload_us_cases(cases)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "# Now, time to create all the USJudges and JudgeRulings\n",
    "\n",
    "# The idea will be to create judges from every single case\n",
    "# Then later collapse this into just the unique judges (which match on every field, since its unclear if orig_name's are unique)\n",
    "\n",
    "# Given a row in the stata file, creates a tuple of USJudges\n",
    "def create_judge_tuple(row):\n",
    "    return (create_judge(row, 1), create_judge(row, 2), create_judge(row, 3))\n",
    "\n",
    "# For a given row and judge number, returns that judge's details as a USJudge object\n",
    "# judgenum = 1, 2 or 3 for judges labelled j1, j2 or j3\n",
    "def create_judge(row, judgenum):\n",
    "    name = judge_property(row, judgenum, \"name\")  # if empty string, return None is what this does\n",
    "    name = None if name == \"\" else name\n",
    "    orig_name = judge_property(row, judgenum, \"Origname\")\n",
    "    name = orig_name if name == None else name # if name is missing replace with the Origname\n",
    "    orig_name = None # otherwise, remove the orig_name, it no longer bears any info and the same person can have two orig names\n",
    "    gender_num = judge_property(row, judgenum, \"gender\")\n",
    "    gender = None if pd.isnull(gender_num) else USJudge.GENDERS[int(gender_num)-1] # 1 is converted to MALE, 2 is converted to FEMALE\n",
    "    party_num = judge_property(row, judgenum, \"party\")\n",
    "    party_num = party_num_cleaning(party_num=party_num, name=name)\n",
    "    party = None if pd.isnull(party_num) else USJudge.PARTIES[1-int(party_num)] # 1 is converted to Democrat, 0 is converted to Republican\n",
    "    senior_num = judge_property(row, judgenum, \"Senior\")\n",
    "    senior = None if pd.isnull(senior_num) else bool(senior_num)\n",
    "\n",
    "    assert name != \"\"\n",
    "    assert orig_name != \"\"\n",
    "    assert gender == USJudge.MALE or gender_num != 1\n",
    "    assert party == USJudge.DEMOCRAT or party_num != 1\n",
    "    assert senior != False or senior_num == 0\n",
    "\n",
    "    return USJudge(name=name, orig_name=orig_name, gender=gender, senior=senior, party=party)\n",
    "\n",
    "# For a given judge and property, returns the property\n",
    "# For example, calling judge_property(row, \"j1\", \"name\") will fetch j1name from the row\n",
    "def judge_property(row, judgenum, judgeprop):\n",
    "    return row[\"j\" + str(judgenum) + judgeprop]\n",
    "\n",
    "# Convert unclean party numbers to 1 for democrat, 0 for republican\n",
    "def party_num_cleaning(party_num, name):\n",
    "    party_num = 0 if name == \"BOND, HUGH LENNOX\" else party_num # BOND Appointed by Ulysses S Grant (R)\n",
    "    party_num = 1 if name == \"HAYS, PAUL\" else party_num # HAYS Appointed by John F Kennedy (D)\n",
    "    party_num = 0 if name == \"MAHONEY, J. DANIEL\" else party_num # MAHONEY Appointed by Ronald Reagan (R)\n",
    "    party_num = 0 if name == \"BURNS, LOUIS HENRY\" else party_num # BURNS Appointed by Calvin Coolidge (R)\n",
    "    party_num = 1 if name == \"BAER, HAROLD, JR.\" else party_num # many Orignames Appointed by Bill Clinton (D) - also a district court judge\n",
    "\n",
    "    party_num = None if party_num == 3 else party_num # unclear what party number of 3 really means, leave it blank for now\n",
    "\n",
    "    return party_num\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "judges_per_case = df.apply(create_judge_tuple, axis=1)\n",
    "\n",
    "print(len(judges_per_case))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "387898\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "# Extract unique judges\n",
    "all_judges = set()\n",
    "for judges in judges_per_case:\n",
    "    (j1, j2, j3) = judges\n",
    "    #assert j1.judge_orig_name != None\n",
    "    #assert j2.judge_orig_name != None\n",
    "    #assert j3.judge_orig_name != None\n",
    "\n",
    "    all_judges.add(j1)\n",
    "    all_judges.add(j2)\n",
    "    all_judges.add(j3)\n",
    "\n",
    "print(len(all_judges))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4502\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "judge_list = list(all_judges)\n",
    "\n",
    "#uploaded_judges = client.upload_us_judges(judge_list)\n",
    "\n",
    "#uploaded_judges = client.get_us_judges() # if running the remaining code after the upload, fetch the uploaded judges again - need their IDs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "print(len(uploaded_judges))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4502\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "from copy import deepcopy\n",
    "# Create dictionary mapping id-less judge to ID\n",
    "judge_id_dict = dict()\n",
    "for judge in uploaded_judges:\n",
    "    idless_judge = deepcopy(judge)\n",
    "    idless_judge.id = None\n",
    "    assert judge.id != None\n",
    "    judge_id_dict[idless_judge] = judge.id"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# create a version of judges_per_case but each judge now has the ID\n",
    "def assign_id(judge):\n",
    "    return_judge = deepcopy(judge)\n",
    "    return_judge.id = judge_id_dict[judge]\n",
    "    return return_judge\n",
    "    \n",
    "judges_per_case_with_id =  [(assign_id(j1), assign_id(j2), assign_id(j3)) for j1,j2,j3 in judges_per_case]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "df['judges_per_case'] = judges_per_case_with_id # add a column for the tuple of judge objects"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "def repopulate_orig_name(row):\n",
    "    # orig names are used in matching judges to whether they were dissenters/concurrers/authors on a case\n",
    "    (j1, j2, j3) = row['judges_per_case']\n",
    "    j1 = deepcopy(j1)\n",
    "    j2 = deepcopy(j2)\n",
    "    j3 = deepcopy(j3)\n",
    "\n",
    "    j1.judge_orig_name = judge_property(row, 1, \"Origname\")\n",
    "    j2.judge_orig_name = judge_property(row, 2, \"Origname\")\n",
    "    j3.judge_orig_name = judge_property(row, 3, \"Origname\")\n",
    "\n",
    "    return (j1, j2, j3)\n",
    "\n",
    "judges_per_case_complete = df.apply(repopulate_orig_name, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "print(len(judges_per_case_complete))\n",
    "df['judges_per_case'] = judges_per_case_complete"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "387898\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "# THIS ENTIRE SECTION IS EXPLORATORY\n",
    "# To see how to handle problems of unclean names\n",
    "# not actually used to execute any action needed to upload judge rulings\n",
    "\n",
    "dissenter_collision = 0\n",
    "dissenter_not_found = 0\n",
    "concurrer_collision = 0\n",
    "concurrer_not_found = 0\n",
    "author_collision = 0\n",
    "author_not_found = 0\n",
    "\n",
    "author_collision_list = []\n",
    "def check_judge_matches(row):\n",
    "    dissenters = row['JudgeDissentingTouse'].split(sep = \"|\")\n",
    "    dissenters = [dissenter.strip().upper()  for dissenter in dissenters if dissenter.strip() != \"\"]\n",
    "    concurrers = row['JudgeconcurringTouse'].split(sep = \"|\")\n",
    "    concurrers = [concurrer.strip().upper() for concurrer in concurrers if concurrer.strip() != \"\"]\n",
    "    author = row['Author']\n",
    "\n",
    "    (j1, j2, j3) = row['judges_per_case']\n",
    "    for dissenter in dissenters:\n",
    "        res = matches_one_judge(j1, j2, j3, dissenter)\n",
    "        if res != True:\n",
    "            if res==\"COLLISION\":\n",
    "                global dissenter_collision\n",
    "                dissenter_collision = dissenter_collision + 1\n",
    "            elif res==\"NOT FOUND\":\n",
    "                global dissenter_not_found\n",
    "                dissenter_not_found = dissenter_not_found + 1\n",
    "    for concurrer in concurrers:\n",
    "        res = matches_one_judge(j1, j2, j3, concurrer)\n",
    "        if res != True:\n",
    "            if res==\"COLLISION\":\n",
    "                global concurrer_collision\n",
    "                concurrer_collision = concurrer_collision + 1\n",
    "            elif res==\"NOT FOUND\":\n",
    "                global concurrer_not_found\n",
    "                concurrer_not_found = concurrer_not_found + 1\n",
    "    if not pd.isnull(author) and author.strip() != \"\" and author != \"PER CURIAM\":\n",
    "        res = matches_one_judge(j1, j2, j3, author)\n",
    "        if res != True:\n",
    "            if res==\"COLLISION\":\n",
    "                global author_collision\n",
    "                author_collision = author_collision + 1\n",
    "                author_collision_list.append((row['caseid'], author, j1, j2, j3))\n",
    "            elif res==\"NOT FOUND\":\n",
    "                global author_not_found\n",
    "                author_not_found = author_not_found + 1\n",
    "\n",
    "def matches_one_judge(j1, j2, j3, dissenter):\n",
    "    # this function is to check that any named dissenter, concurrer or author\n",
    "    # corresponds to exactly one judge\n",
    "    # IE isn't typo'ed and corresponds to no judge\n",
    "    # isn't confusingly possibly two different judges\n",
    "\n",
    "    # Tries to match by name and by orig name\n",
    "    res = name_matches_one(j1, j2, j3, dissenter)\n",
    "    if res == True:\n",
    "        # if matched, carry one\n",
    "        return True\n",
    "    else:\n",
    "        res_orig = orig_name_matches_one(j1, j2, j3, dissenter)\n",
    "        if res_orig == True:\n",
    "            return True # can be matched by orig_name at least\n",
    "        else:\n",
    "            if res_orig == \"COLLISION\":\n",
    "                res_exact = orig_name_matches_one_exactly(j1, j2, j3, dissenter)\n",
    "                if res_exact == True:\n",
    "                    return True\n",
    "    return res\n",
    "        \n",
    "def name_matches_one(j1, j2, j3, dissenter):\n",
    "    # this function is to check that any named dissenter, concurrer or author\n",
    "    # corresponds to exactly one judge\n",
    "    # IE isn't typo'ed and corresponds to no judge\n",
    "    # isn't confusingly possibly two different judges\n",
    "    if dissenter in j1.judge_name or dissenter in j2.judge_name or dissenter in j3.judge_name:\n",
    "        # check they don't appear in two different judges names\n",
    "        if not (dissenter in j1.judge_name and dissenter in j2.judge_name) \\\n",
    "            and not (dissenter in j2.judge_name and dissenter in j3.judge_name) \\\n",
    "                and not (dissenter in j1.judge_name and dissenter in j3.judge_name):\n",
    "                return True\n",
    "        else:\n",
    "            return \"COLLISION\"\n",
    "    else:\n",
    "        return \"NOT FOUND\"\n",
    "        \n",
    "\n",
    "def orig_name_matches_one(j1, j2, j3, dissenter):\n",
    "    # Same as above, but using orig_names\n",
    "    if dissenter in j1.judge_orig_name or dissenter in j2.judge_orig_name or dissenter in j3.judge_orig_name:\n",
    "        # check they don't appear in two different judges names\n",
    "        if not (dissenter in j1.judge_orig_name and dissenter in j2.judge_orig_name) \\\n",
    "            and not (dissenter in j2.judge_orig_name and dissenter in j3.judge_orig_name) \\\n",
    "                and not (dissenter in j1.judge_orig_name and dissenter in j3.judge_orig_name):\n",
    "                return True\n",
    "        else:\n",
    "            return \"COLLISION\"\n",
    "    else:\n",
    "        return \"NOT FOUND\"\n",
    "\n",
    "def orig_name_matches_one_exactly(j1, j2, j3, dissenter):\n",
    "    # Same as above, but using exact equality (to settle conflicts)\n",
    "    if dissenter == j1.judge_orig_name or dissenter == j2.judge_orig_name or dissenter == j3.judge_orig_name:\n",
    "        # check they don't appear in two different judges names\n",
    "        if not (dissenter == j1.judge_orig_name and dissenter == j2.judge_orig_name) \\\n",
    "            and not (dissenter == j2.judge_orig_name and dissenter == j3.judge_orig_name) \\\n",
    "                and not (dissenter == j1.judge_orig_name and dissenter == j3.judge_orig_name):\n",
    "                return True\n",
    "        else:\n",
    "            return \"COLLISION\"\n",
    "    else:\n",
    "        return \"NOT FOUND\"\n",
    "#def create_judge_ruling(judge, caseid, dissenters, concurrers, author):\n",
    "    #for \n",
    "\n",
    "df.apply(check_judge_matches, axis = 1)\n",
    "print(\"Dissenter collison\", dissenter_collision)\n",
    "print(\"Dissenter not found\", dissenter_not_found)\n",
    "print(\"Concurrer collison\", concurrer_collision)\n",
    "print(\"Concurrer not found\", concurrer_not_found)\n",
    "print(\"Author collison\", author_collision)\n",
    "print(\"Author not found\", author_not_found)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dissenter collison 3\n",
      "Dissenter not found 2451\n",
      "Concurrer collison 2\n",
      "Concurrer not found 1507\n",
      "Author collison 47\n",
      "Author not found 11485\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "problematic_author_names = set()\n",
    "problematic_caseids = list()\n",
    "for author_coll in author_collision_list:\n",
    "    (caseid, name, _, _, _) = author_coll\n",
    "    problematic_author_names.add(name)\n",
    "    problematic_caseids.append(caseid)\n",
    "\n",
    "print(len(problematic_author_names))\n",
    "print(problematic_author_names)\n",
    "#print(author_collision_list)\n",
    "(df[df.caseid.isin(problematic_caseids)])[[\"caseid\", \"j1name\", \"j2name\", \"j3name\", \"Author\"]]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12\n",
      "{'THOMPSON', 'GIBSON', 'NELSON', 'WOOD', 'MICHAEL', 'WILLIAMS', 'NEWMAN', 'PHILLIPS', 'ARNOLD', 'ANDERSON', 'CARNES', 'GINSBURG'}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "('caseid', 'j1name', 'j2name', 'j3name', 'Author')",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Programming/Python/stata-to-repo/venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('caseid', 'j1name', 'j2name', 'j3name', 'Author')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-0cd89e295e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblematic_author_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#print(author_collision_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaseid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblematic_caseids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"caseid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"j1name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"j2name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"j3name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Author\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Programming/Python/stata-to-repo/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Programming/Python/stata-to-repo/venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('caseid', 'j1name', 'j2name', 'j3name', 'Author')"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "4d2961f35c2819ad27aef0630749d17fc7f9b9fe09bbacd82eca82e48911dd16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}